#!/bin/tcsh

#SBATCH --job-name="evaluate_models_efficient"
#SBATCH --partition="fge"
#SBATCH --account="rda-ghpcs"
#SBATCH --qos="batch"
#SBATCH --ntasks=1
#SBATCH --nodes=1
#SBATCH --cpus-per-task=1
#SBATCH --mem=24G
#SBATCH --time=01:00:00
#SBATCH --array=1-100
##SBATCH --exclude=h31n03,h28n12
##SBATCH --exclude=h29n01,h26n05,h28n06,h29n07,h30n03,h30n15
#SBATCH --mail-type=BEGIN,END,FAIL
#SBATCH --mail-user=ryan.lagerquist@noaa.gov
#SBATCH --output=evaluate_models_efficient_%A_%a.out

module load cuda/10.1
source /scratch2/BMC/gsd-hpcs/Jebb.Q.Stewart/conda3.7/etc/profile.d/conda.csh
conda activate base

set CODE_DIR_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml4rt_standalone/ml4rt"
set TOP_MODEL_DIR_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml4rt_models/experiment09"

set DENSE_LAYER_COUNTS=(4)
set DENSE_LAYER_DROPOUT_RATES=(0.000)
set L2_WEIGHTS=(0.0000001000)
set FIRST_BOOTSTRAP_REP_INDICES=(0 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350 360 370 380 390 400 410 420 430 440 450 460 470 480 490 500 510 520 530 540 550 560 570 580 590 600 610 620 630 640 650 660 670 680 690 700 710 720 730 740 750 760 770 780 790 800 810 820 830 840 850 860 870 880 890 900 910 920 930 940 950 960 970 980 990)
set LAST_BOOTSTRAP_REP_INDICES=(9 19 29 39 49 59 69 79 89 99 109 119 129 139 149 159 169 179 189 199 209 219 229 239 249 259 269 279 289 299 309 319 329 339 349 359 369 379 389 399 409 419 429 439 449 459 469 479 489 499 509 519 529 539 549 559 569 579 589 599 609 619 629 639 649 659 669 679 689 699 709 719 729 739 749 759 769 779 789 799 809 819 829 839 849 859 869 879 889 899 909 919 929 939 949 959 969 979 989 999)

set dense_layer_count=${DENSE_LAYER_COUNTS[1]}
set dense_layer_dropout_rate=${DENSE_LAYER_DROPOUT_RATES[1]}
set l2_weight=${L2_WEIGHTS[1]}
set first_bootstrap_rep_index=${FIRST_BOOTSTRAP_REP_INDICES[$SLURM_ARRAY_TASK_ID]}
set last_bootstrap_rep_index=${LAST_BOOTSTRAP_REP_INDICES[$SLURM_ARRAY_TASK_ID]}

set dense_layer_count_string=`printf "%d" $dense_layer_count`
set dense_layer_dropout_string=`printf "%.3f" $dense_layer_dropout_rate`
set l2_weight_string=`printf "%.10f" $l2_weight`
set first_bootstrap_rep_string=`printf "%03d" $first_bootstrap_rep_index`
set last_bootstrap_rep_string=`printf "%03d" $last_bootstrap_rep_index`

set top_model_dir_name="${TOP_MODEL_DIR_NAME}/num-dense-layers=${dense_layer_count_string}_dense-dropout=${dense_layer_dropout_string}_l2-weight=${l2_weight_string}"

set model_file_names={${top_model_dir_name}/model*.h5}
set model_file_name=${model_file_names[$#model_file_names]}
set model_dir_name=`echo $model_file_name | rev | cut -c 4- | rev`

set prediction_file_name="${model_dir_name}/isotonic_regression/training_eval_with_bootstrap/predictions.nc"
set testing_dir_name="${model_dir_name}/isotonic_regression/training_eval_with_bootstrap/bootstrap_reps_${first_bootstrap_rep_string}-${last_bootstrap_rep_string}"

python3 -u "${CODE_DIR_NAME}/evaluate_neural_net.py" \
--input_prediction_file_name="${prediction_file_name}" \
--num_bootstrap_reps=10 \
--output_dir_name="${testing_dir_name}"
