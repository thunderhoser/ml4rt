#!/bin/tcsh

#SBATCH --job-name="train_neural_nets"
#SBATCH --partition="fge"
#SBATCH --account="rda-ghpcs"
#SBATCH --qos="batch"
#SBATCH --nodes=1
#SBATCH --ntasks=8           # 8 tasks per node
#SBATCH --cpus-per-task=2
#SBATCH --ntasks-per-node=8  # 8 GPUs per node
#SBATCH --exclusive
#SBATCH --time=30:00:00
#SBATCH --array=1-216%75
#SBATCH --exclude=h28n12
##SBATCH --exclude=h31n03,h28n12
##SBATCH --exclude=h29n01,h26n05,h28n06,h29n07,h30n03,h30n15
#SBATCH --mail-type=BEGIN,END,FAIL
#SBATCH --mail-user=ryan.lagerquist@noaa.gov
#SBATCH --output=train_neural_nets_%A_%a.out

module load cuda/10.1
source /scratch2/BMC/gsd-hpcs/Jebb.Q.Stewart/conda3.7/etc/profile.d/conda.csh
conda activate base

set CODE_DIR_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml4rt_standalone_sr/ml4rt"
set TEMPLATE_DIR_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml4rt_models/experiment09/templates"
set TOP_OUTPUT_DIR_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml4rt_models/experiment09"

set TRAINING_DIR_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml4rt_project/examples/assorted1_sites"
set VALIDATION_DIR_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml4rt_project/examples/assorted1_sites"
set NORMALIZATION_FILE_NAME="${TRAINING_DIR_NAME}/learning_examples_20190101-20201031.nc"

set DENSE_LAYER_COUNTS=(2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5)
set DENSE_LAYER_DROPOUT_RATES=(0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.200 0.200 0.200 0.200 0.200 0.200 0.200 0.200 0.200 0.200 0.200 0.200 0.200 0.200 0.200 0.200 0.200 0.200 0.200 0.200 0.200 0.200 0.200 0.200 0.200 0.200 0.200 0.200 0.200 0.200 0.200 0.200 0.200 0.200 0.200 0.200 0.300 0.300 0.300 0.300 0.300 0.300 0.300 0.300 0.300 0.300 0.300 0.300 0.300 0.300 0.300 0.300 0.300 0.300 0.300 0.300 0.300 0.300 0.300 0.300 0.300 0.300 0.300 0.300 0.300 0.300 0.300 0.300 0.300 0.300 0.300 0.300 0.400 0.400 0.400 0.400 0.400 0.400 0.400 0.400 0.400 0.400 0.400 0.400 0.400 0.400 0.400 0.400 0.400 0.400 0.400 0.400 0.400 0.400 0.400 0.400 0.400 0.400 0.400 0.400 0.400 0.400 0.400 0.400 0.400 0.400 0.400 0.400 0.500 0.500 0.500 0.500 0.500 0.500 0.500 0.500 0.500 0.500 0.500 0.500 0.500 0.500 0.500 0.500 0.500 0.500 0.500 0.500 0.500 0.500 0.500 0.500 0.500 0.500 0.500 0.500 0.500 0.500 0.500 0.500 0.500 0.500 0.500 0.500)
set L2_WEIGHTS=(0.0000001000 0.0000003162 0.0000010000 0.0000031623 0.0000100000 0.0000316228 0.0001000000 0.0003162278 0.0010000000 0.0000001000 0.0000003162 0.0000010000 0.0000031623 0.0000100000 0.0000316228 0.0001000000 0.0003162278 0.0010000000 0.0000001000 0.0000003162 0.0000010000 0.0000031623 0.0000100000 0.0000316228 0.0001000000 0.0003162278 0.0010000000 0.0000001000 0.0000003162 0.0000010000 0.0000031623 0.0000100000 0.0000316228 0.0001000000 0.0003162278 0.0010000000 0.0000001000 0.0000003162 0.0000010000 0.0000031623 0.0000100000 0.0000316228 0.0001000000 0.0003162278 0.0010000000 0.0000001000 0.0000003162 0.0000010000 0.0000031623 0.0000100000 0.0000316228 0.0001000000 0.0003162278 0.0010000000 0.0000001000 0.0000003162 0.0000010000 0.0000031623 0.0000100000 0.0000316228 0.0001000000 0.0003162278 0.0010000000 0.0000001000 0.0000003162 0.0000010000 0.0000031623 0.0000100000 0.0000316228 0.0001000000 0.0003162278 0.0010000000 0.0000001000 0.0000003162 0.0000010000 0.0000031623 0.0000100000 0.0000316228 0.0001000000 0.0003162278 0.0010000000 0.0000001000 0.0000003162 0.0000010000 0.0000031623 0.0000100000 0.0000316228 0.0001000000 0.0003162278 0.0010000000 0.0000001000 0.0000003162 0.0000010000 0.0000031623 0.0000100000 0.0000316228 0.0001000000 0.0003162278 0.0010000000 0.0000001000 0.0000003162 0.0000010000 0.0000031623 0.0000100000 0.0000316228 0.0001000000 0.0003162278 0.0010000000 0.0000001000 0.0000003162 0.0000010000 0.0000031623 0.0000100000 0.0000316228 0.0001000000 0.0003162278 0.0010000000 0.0000001000 0.0000003162 0.0000010000 0.0000031623 0.0000100000 0.0000316228 0.0001000000 0.0003162278 0.0010000000 0.0000001000 0.0000003162 0.0000010000 0.0000031623 0.0000100000 0.0000316228 0.0001000000 0.0003162278 0.0010000000 0.0000001000 0.0000003162 0.0000010000 0.0000031623 0.0000100000 0.0000316228 0.0001000000 0.0003162278 0.0010000000 0.0000001000 0.0000003162 0.0000010000 0.0000031623 0.0000100000 0.0000316228 0.0001000000 0.0003162278 0.0010000000 0.0000001000 0.0000003162 0.0000010000 0.0000031623 0.0000100000 0.0000316228 0.0001000000 0.0003162278 0.0010000000 0.0000001000 0.0000003162 0.0000010000 0.0000031623 0.0000100000 0.0000316228 0.0001000000 0.0003162278 0.0010000000 0.0000001000 0.0000003162 0.0000010000 0.0000031623 0.0000100000 0.0000316228 0.0001000000 0.0003162278 0.0010000000 0.0000001000 0.0000003162 0.0000010000 0.0000031623 0.0000100000 0.0000316228 0.0001000000 0.0003162278 0.0010000000 0.0000001000 0.0000003162 0.0000010000 0.0000031623 0.0000100000 0.0000316228 0.0001000000 0.0003162278 0.0010000000 0.0000001000 0.0000003162 0.0000010000 0.0000031623 0.0000100000 0.0000316228 0.0001000000 0.0003162278 0.0010000000 0.0000001000 0.0000003162 0.0000010000 0.0000031623 0.0000100000 0.0000316228 0.0001000000 0.0003162278 0.0010000000)

set dense_layer_count=${DENSE_LAYER_COUNTS[$SLURM_ARRAY_TASK_ID]}
set dense_layer_dropout_rate=${DENSE_LAYER_DROPOUT_RATES[$SLURM_ARRAY_TASK_ID]}
set l2_weight=${L2_WEIGHTS[$SLURM_ARRAY_TASK_ID]}

set dense_layer_count_string=`printf "%d" $dense_layer_count`
set dense_layer_dropout_string=`printf "%.3f" $dense_layer_dropout_rate`
set l2_weight_string=`printf "%.10f" $l2_weight`

set template_file_name="${TEMPLATE_DIR_NAME}/model_num-dense-layers=${dense_layer_count_string}_dense-dropout=${dense_layer_dropout_string}_l2-weight=${l2_weight_string}.h5"
set output_dir_name="${TOP_OUTPUT_DIR_NAME}/num-dense-layers=${dense_layer_count_string}_dense-dropout=${dense_layer_dropout_string}_l2-weight=${l2_weight_string}"
echo $output_dir_name

python3 -u "${CODE_DIR_NAME}/train_neural_net.py" \
--net_type_string="u_net" \
--input_training_dir_name="${TRAINING_DIR_NAME}" \
--input_validation_dir_name="${VALIDATION_DIR_NAME}" \
--input_normalization_file_name="${NORMALIZATION_FILE_NAME}" \
--input_model_file_name="${template_file_name}" \
--output_model_dir_name="${output_dir_name}" \
--use_generator_for_training=0 \
--use_generator_for_validn=0 \
--target_names "shortwave_heating_rate_k_day01" "shortwave_surface_down_flux_w_m02" "shortwave_toa_up_flux_w_m02" \
--heights_m_agl 10 20 40 60 80 100 120 140 160 180 200 225 250 275 300 350 400 450 500 600 700 800 900 1000 1100 1200 1300 1400 1500 1600 1700 1800 1900 2000 2200 2400 2600 2800 3000 3200 3400 3600 3800 4000 4200 4400 4600 4800 5000 5500 6000 6500 7000 8000 9000 10000 11000 12000 13000 14000 15000 18000 20000 22000 24000 27000 30000 33000 36000 39000 42000 46000 50000 \
--omit_heating_rate=0 \
--first_training_time_string="2019-01-01-000000" \
--last_training_time_string="2020-12-31-235959" \
--first_validn_time_string="2018-01-01-000000" \
--last_validn_time_string="2018-12-24-235959" \
--vector_target_norm_type_string='' \
--scalar_target_norm_type_string='minmax' \
--scalar_target_min_norm_value=0 \
--scalar_target_max_norm_value=1 \
--num_examples_per_batch=256 \
--plateau_lr_multiplier=0.6
