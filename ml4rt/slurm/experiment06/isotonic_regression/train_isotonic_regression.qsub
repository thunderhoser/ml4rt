#!/bin/tcsh

#SBATCH --job-name="train_isotonic_regression"
#SBATCH --partition="fge"
#SBATCH --account="rda-ghpcs"
#SBATCH --qos="batch"
#SBATCH --ntasks=1
#SBATCH --nodes=1
#SBATCH --cpus-per-task=1
#SBATCH --mem=32G
##SBATCH --nodes=1
##SBATCH --ntasks=1
##SBATCH --cpus-per-task=1
##SBATCH --ntasks-per-node=1
#SBATCH --time=02:00:00
#SBATCH --array=1-144
#SBATCH --exclude=h28n12
##SBATCH --exclude=h31n03,h28n12
##SBATCH --exclude=h29n01,h26n05,h28n06,h29n07,h30n03,h30n15
#SBATCH --mail-type=BEGIN,END,FAIL
#SBATCH --mail-user=ryan.lagerquist@noaa.gov
#SBATCH --output=train_isotonic_regression_%A_%a.out

module load cuda/10.1
source /scratch2/BMC/gsd-hpcs/Jebb.Q.Stewart/conda3.7/etc/profile.d/conda.csh
conda activate base

set CODE_DIR_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml4rt_standalone_sr/ml4rt"
set TOP_MODEL_DIR_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml4rt_models/experiment06"
set TRAINING_DIR_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml4rt_project/examples/non_tropical_sites"

set FIRST_TRAINING_TIME_STRING="2019-01-01-000000"
set LAST_TRAINING_TIME_STRING="2019-12-24-235959"

set DENSE_LAYER_COUNTS=(2 2 2 2 2 2 3 3 3 3 3 3 4 4 4 4 4 4 5 5 5 5 5 5 2 2 2 2 2 2 3 3 3 3 3 3 4 4 4 4 4 4 5 5 5 5 5 5 2 2 2 2 2 2 3 3 3 3 3 3 4 4 4 4 4 4 5 5 5 5 5 5 2 2 2 2 2 2 3 3 3 3 3 3 4 4 4 4 4 4 5 5 5 5 5 5 2 2 2 2 2 2 3 3 3 3 3 3 4 4 4 4 4 4 5 5 5 5 5 5 2 2 2 2 2 2 3 3 3 3 3 3 4 4 4 4 4 4 5 5 5 5 5 5)
set DENSE_LAYER_DROPOUT_RATES=(0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.100 0.200 0.200 0.200 0.200 0.200 0.200 0.200 0.200 0.200 0.200 0.200 0.200 0.200 0.200 0.200 0.200 0.200 0.200 0.200 0.200 0.200 0.200 0.200 0.200 0.300 0.300 0.300 0.300 0.300 0.300 0.300 0.300 0.300 0.300 0.300 0.300 0.300 0.300 0.300 0.300 0.300 0.300 0.300 0.300 0.300 0.300 0.300 0.300 0.400 0.400 0.400 0.400 0.400 0.400 0.400 0.400 0.400 0.400 0.400 0.400 0.400 0.400 0.400 0.400 0.400 0.400 0.400 0.400 0.400 0.400 0.400 0.400 0.500 0.500 0.500 0.500 0.500 0.500 0.500 0.500 0.500 0.500 0.500 0.500 0.500 0.500 0.500 0.500 0.500 0.500 0.500 0.500 0.500 0.500 0.500 0.500)
set SCALAR_LOSS_FUNCTION_WEIGHTS=(1.0 2.5 5.0 10.0 25.0 50.0 1.0 2.5 5.0 10.0 25.0 50.0 1.0 2.5 5.0 10.0 25.0 50.0 1.0 2.5 5.0 10.0 25.0 50.0 1.0 2.5 5.0 10.0 25.0 50.0 1.0 2.5 5.0 10.0 25.0 50.0 1.0 2.5 5.0 10.0 25.0 50.0 1.0 2.5 5.0 10.0 25.0 50.0 1.0 2.5 5.0 10.0 25.0 50.0 1.0 2.5 5.0 10.0 25.0 50.0 1.0 2.5 5.0 10.0 25.0 50.0 1.0 2.5 5.0 10.0 25.0 50.0 1.0 2.5 5.0 10.0 25.0 50.0 1.0 2.5 5.0 10.0 25.0 50.0 1.0 2.5 5.0 10.0 25.0 50.0 1.0 2.5 5.0 10.0 25.0 50.0 1.0 2.5 5.0 10.0 25.0 50.0 1.0 2.5 5.0 10.0 25.0 50.0 1.0 2.5 5.0 10.0 25.0 50.0 1.0 2.5 5.0 10.0 25.0 50.0 1.0 2.5 5.0 10.0 25.0 50.0 1.0 2.5 5.0 10.0 25.0 50.0 1.0 2.5 5.0 10.0 25.0 50.0 1.0 2.5 5.0 10.0 25.0 50.0)

set dense_layer_count=${DENSE_LAYER_COUNTS[$SLURM_ARRAY_TASK_ID]}
set dense_layer_dropout_rate=${DENSE_LAYER_DROPOUT_RATES[$SLURM_ARRAY_TASK_ID]}
set scalar_loss_function_weight=${SCALAR_LOSS_FUNCTION_WEIGHTS[$SLURM_ARRAY_TASK_ID]}

set dense_layer_count_string=`printf "%d" $dense_layer_count`
set dense_layer_dropout_string=`printf "%.3f" $dense_layer_dropout_rate`
set scalar_loss_function_weight_string=`printf "%05.1f" $scalar_loss_function_weight`
set top_model_dir_name="${TOP_MODEL_DIR_NAME}/num-dense-layers=${dense_layer_count_string}_dense-dropout=${dense_layer_dropout_string}_scalar-lf-weight=${scalar_loss_function_weight_string}"

set model_file_names={${top_model_dir_name}/model*.h5}
set model_file_name=${model_file_names[$#model_file_names]}
set model_dir_name=`echo $model_file_name | rev | cut -c 4- | rev`

set isotonic_dir_name="${model_dir_name}/isotonic_regression"
set orig_prediction_file_name="${isotonic_dir_name}/orig_predictions.nc"

python3 -u "${CODE_DIR_NAME}/apply_neural_net.py" \
--input_model_file_name="${model_file_name}" \
--input_example_dir_name="${TRAINING_DIR_NAME}" \
--first_time_string="${FIRST_TRAINING_TIME_STRING}" \
--last_time_string="${LAST_TRAINING_TIME_STRING}" \
--output_file_name="${orig_prediction_file_name}"

python3 -u "${CODE_DIR_NAME}/train_isotonic_regression.py" \
--input_prediction_file_name="${orig_prediction_file_name}" \
--separate_by_height=1 \
--output_model_dir_name="${isotonic_dir_name}"
