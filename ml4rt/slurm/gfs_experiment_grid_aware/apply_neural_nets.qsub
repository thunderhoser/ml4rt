#!/bin/tcsh

#SBATCH --job-name="apply_neural_nets"
#SBATCH --partition="fge"
#SBATCH --account="rda-ghpcs"
#SBATCH --qos="batch"
#SBATCH --ntasks=1
#SBATCH --nodes=1
#SBATCH --cpus-per-task=1
##SBATCH --nodes=1
##SBATCH --ntasks=1
##SBATCH --cpus-per-task=1
##SBATCH --ntasks-per-node=1
#SBATCH --time=02:00:00
#SBATCH --array=1-12
#SBATCH --exclude=h28n12
##SBATCH --exclude=h31n03,h28n12
##SBATCH --exclude=h29n01,h26n05,h28n06,h29n07,h30n03,h30n15
#SBATCH --mail-type=BEGIN,END,FAIL
#SBATCH --mail-user=ryan.lagerquist@noaa.gov
#SBATCH --output=apply_neural_nets_%A_%a.out

module load cuda/10.1
source /scratch2/BMC/gsd-hpcs/Jebb.Q.Stewart/conda3.7/etc/profile.d/conda.csh
conda activate base

set CODE_DIR_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml4rt_standalone/ml4rt"
set TOP_MODEL_DIR_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml4rt_models/gfs_experiment_grid_aware"

set FIRST_VALIDN_TIME_STRING="2020-03-16-000000"
set LAST_VALIDN_TIME_STRING="2020-04-15-235959"

set USE_GENERATOR_FLAGS=(0 0 0 1 1 1 0 0 0 1 1 1)
set EXAMPLES_PER_BATCH_COUNTS=(181 181 181 362 362 362 724 724 724 362 362 362)
set BATCHES_PER_EPOCH_COUNTS=(3000 3000 3000 750 750 750 5000 5000 5000 500 500 500)
set USE_HEIGHT_FLAGS=(0 1 1 0 1 1 0 1 1 0 1 1)
set MULTIPLY_BY_THICKNESS_FLAGS=(1 0 1 1 0 1 1 0 1 1 0 1)

set use_generator_flag=${USE_GENERATOR_FLAGS[$SLURM_ARRAY_TASK_ID]}
set num_examples_per_batch=${EXAMPLES_PER_BATCH_COUNTS[$SLURM_ARRAY_TASK_ID]}
set num_batches_per_epoch=${BATCHES_PER_EPOCH_COUNTS[$SLURM_ARRAY_TASK_ID]}
set use_height_flag=${USE_HEIGHT_FLAGS[$SLURM_ARRAY_TASK_ID]}
set multiply_by_thickness_flag=${MULTIPLY_BY_THICKNESS_FLAGS[$SLURM_ARRAY_TASK_ID]}

set use_generator_flag_string=`printf "%1d" $use_generator_flag`
set num_examples_per_batch_string=`printf "%03d" $num_examples_per_batch`
set num_batches_per_epoch_string=`printf "%04d" $num_batches_per_epoch`
set use_height_flag_string=`printf "%1d" $use_height_flag`
set multiply_by_thickness_flag_string=`printf "%1d" $multiply_by_thickness_flag`

set top_model_dir_name="${TOP_MODEL_DIR_NAME}/use-generator=${use_generator_flag_string}_num-examples-per-batch=${num_examples_per_batch_string}_num-batches-per-epoch=${num_batches_per_epoch_string}_use-height=${use_height_flag_string}_multiply-by-layer-thickness=${multiply_by_thickness_flag_string}"

set model_file_names={${top_model_dir_name}/model*.h5}
set model_file_name=${model_file_names[$#model_file_names]}
set model_dir_name=`echo $model_file_name | rev | cut -c 4- | rev`
set prediction_file_name="${model_dir_name}/validation/predictions.nc"

if ($multiply_by_thickness_flag > 0) then
    set example_dir_name="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml4rt_project/gfs_data/examples/orig_heights/normalized_with_layer_thickness/validation"
else
    set example_dir_name="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml4rt_project/gfs_data/examples/orig_heights/normalized/validation"
endif

python3 -u "${CODE_DIR_NAME}/apply_neural_net.py" \
--input_model_file_name="${model_file_name}" \
--input_example_dir_name="${example_dir_name}" \
--first_time_string="${FIRST_VALIDN_TIME_STRING}" \
--last_time_string="${LAST_VALIDN_TIME_STRING}" \
--output_file_name="${prediction_file_name}"
